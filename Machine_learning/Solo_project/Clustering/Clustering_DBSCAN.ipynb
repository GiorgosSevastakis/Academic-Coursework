{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skfeature.function.similarity_based import lap_score\n",
    "from skfeature.utility import construct_W\n",
    "\n",
    "from clusteval import clusteval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "scaler = StandardScaler()\n",
    "\n",
    "Data_train = pd.read_csv('AppML_InitialProject_test_clustering.csv')\n",
    "\n",
    "Data_train = pd.DataFrame(scaler.fit_transform(Data_train), columns=Data_train.columns)\n",
    "\n",
    "X = Data_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the most important features using the **laplacian score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features based on Laplacian Score:\n",
      "['pX_E5x7_Lr1', 'pX_ptvarcone40', 'pX_topoetcone20ptCorrection', 'pX_E_Lr2_LowG', 'pX_emins1', 'pX_nCells_Lr1_LowG', 'pX_deltaEta0', 'pX_deltaPhi2', 'pX_etcone30', 'pX_nCells_Lr1_HiG']\n"
     ]
    }
   ],
   "source": [
    "kwargs_W = {\"metric\": \"euclidean\", \"neighbor_mode\": \"knn\", \"weight_mode\": \"heat_kernel\", \"k\": 5, 't': 1}\n",
    "W = construct_W.construct_W(X.to_numpy(), **kwargs_W)\n",
    "\n",
    "laplacian_scores = lap_score.lap_score(X.to_numpy(), W=W)\n",
    "\n",
    "sorted_indices = np.argsort(laplacian_scores)\n",
    "\n",
    "top_10_features = Data_train.columns[sorted_indices[:10]].tolist()\n",
    "\n",
    "print(\"Top 10 Features based on Laplacian Score:\")\n",
    "print(top_10_features)\n",
    "\n",
    "X_10 = X[top_10_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised clustering using **DBSCAN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2362\n",
      "Number of clusters: 6\n",
      "labels: [0 0 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.66, min_samples=10, n_jobs = -1)\n",
    "dbscan.fit(X_10)\n",
    "\n",
    "labels = dbscan.labels_\n",
    "n_noise_ = list(labels).count(-1)\n",
    "print(n_noise_)\n",
    "\n",
    "print('Number of clusters:', np.max(labels) + 1)\n",
    "print('labels:', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 64.43825674057007 seconds\n"
     ]
    }
   ],
   "source": [
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving (set to False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'solutions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "Write = False\n",
    "if Write:\n",
    "    variables = top_10_features\n",
    "\n",
    "    csv_file_path = os.path.join(folder_name, 'Clustering_DBSCAN_VariableList.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for variable in variables:\n",
    "            writer.writerow([variable])\n",
    "    \n",
    "    data = np.array(list(labels)).astype(float)\n",
    "    csv_file_path = os.path.join(folder_name, 'Clustering_DBSCAN.csv')\n",
    "    \n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for index, item in enumerate(data, start=0):\n",
    "            writer.writerow([index, item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
