{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import precision_score, confusion_matrix, accuracy_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from hyperopt import hp, tpe, fmin, Trials, space_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run to find the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "Data_train = pd.read_csv('AppML_InitialProject_train.csv')\n",
    "\n",
    "X = Data_train.drop(['p_Truth_isElectron', 'p_Truth_Energy'], axis=1)\n",
    "y = Data_train['p_Truth_isElectron']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(objective='binary:logistic', learning_rate=0.1,\n",
    "                            max_depth=8, eval_metric='logloss', n_estimators=300,\n",
    "                            seed=42, use_label_encoder=False, n_jobs = -1)\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_clf.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Selecting the 20 most important features###\n",
    "importances = xgb_clf.feature_importances_\n",
    "sorted_indices = importances.argsort()[::-1]\n",
    "top_20_indices = sorted_indices[:20]\n",
    "top_20_features = X.columns[top_20_indices]\n",
    "\n",
    "X_train_20 = X_train[top_20_features]\n",
    "X_val_20 = X_val[top_20_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second run with **hyperparameter optimization** and **cross validation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Also third run with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [25:15<00:00, 151.54s/trial, best loss: 0.07089634871367259]\n",
      "Best Hyperparameters: {'colsample_bytree': 0.7838522963083432, 'gamma': 0.7018822402097628, 'learning_rate': 0.05306630350590696, 'max_depth': 8, 'min_child_weight': 9.827462508018204, 'n_estimators': 700, 'subsample': 0.6858906365814332}\n",
      "Accuracy: 0.9733777777777778\n",
      "Confusion matrix: [[35196   470]\n",
      " [  728  8606]]\n",
      "LogLoss: 0.07175243804333949\n",
      "Elapsed time: 39.316006660461426 seconds\n"
     ]
    }
   ],
   "source": [
    "###Hyperparameter tuning with Bayes search and cross-validation###\n",
    "\n",
    "X_20 = X[top_20_features]\n",
    "\n",
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 11, dtype=int)),\n",
    "    'subsample': hp.uniform('subsample', 0.5, 1),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "    'gamma': hp.uniform('gamma', 0, 1),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 1000, 100, dtype=int)),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 10)\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', seed=42, use_label_encoder=False, **params, n_jobs = -1)\n",
    "    scores = cross_val_score(model, X_20, y, cv=5, scoring='neg_log_loss')\n",
    "    return -np.mean(scores)\n",
    "\n",
    "##Hyperparameter optimization##\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "best_model = xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss', seed=42, use_label_encoder=False, **best_params, n_jobs = -1)\n",
    "start_time = time.time()\n",
    "best_model.fit(X_train_20, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred_proba = best_model.predict_proba(X_val_20)[:, 1]\n",
    "\n",
    "##Evaluation##\n",
    "accuracy = accuracy_score(y_val, y_pred_proba.round())\n",
    "conf_matrix = confusion_matrix(y_val, y_pred_proba.round())\n",
    "logloss = log_loss(y_val, y_pred_proba)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Confusion matrix:\", conf_matrix)\n",
    "print(\"LogLoss:\", logloss)\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9953282e-01 9.1819185e-01 3.0162913e-01 ... 1.1910958e-02 3.1416648e-04\n",
      " 3.2807007e-03]\n"
     ]
    }
   ],
   "source": [
    "Data_test = pd.read_csv('AppML_InitialProject_test_classification.csv')\n",
    "\n",
    "X_test = pd.DataFrame(scaler.fit_transform(Data_test), columns=Data_test.columns)\n",
    "X_test_20 = X_test[top_20_features]\n",
    "y_pred_prob = best_model.predict_proba(X_test_20)[:, 1]\n",
    "\n",
    "print(y_pred_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving (set to False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'solutions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "Write = False\n",
    "if Write:\n",
    "\n",
    "    top_20_features_list = top_20_features.tolist()\n",
    "    variables = top_20_features\n",
    "    \n",
    "    csv_file_path = os.path.join(folder_name, 'Classification_XGBoost_VariableList.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for variable in variables:\n",
    "            writer.writerow([variable])\n",
    "    \n",
    "    data = y_pred_prob\n",
    "    \n",
    "    csv_file_path = os.path.join(folder_name, 'Classification_XGBoost.csv')\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for index, item in enumerate(data, start=0):\n",
    "            writer.writerow([index, item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
