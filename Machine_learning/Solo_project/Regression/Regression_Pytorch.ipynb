{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from scipy.stats import randint, uniform\n",
    "from random import choice\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run and selection of the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_train = pd.read_csv('AppML_InitialProject_train.csv')\n",
    "Data_train = Data_train[Data_train['p_Truth_isElectron'] == 1]\n",
    "\n",
    "y_mean = np.copy(np.mean(Data_train['p_Truth_Energy']))\n",
    "y_std = np.copy(np.std(Data_train['p_Truth_Energy']))\n",
    "\n",
    "scaler = StandardScaler()\n",
    "Data_train = pd.DataFrame(scaler.fit_transform(Data_train), columns=Data_train.columns)\n",
    "\n",
    "X = Data_train.drop(['p_Truth_isElectron', 'p_Truth_Energy'], axis=1)\n",
    "y = Data_train['p_Truth_Energy']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_val_tensor = torch.tensor(X_val.values, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.hidden_dim1 = hidden_dim1\n",
    "        self.hidden_dim2 = hidden_dim2\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim1)\n",
    "        self.fc2 = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.fc3 = nn.Linear(hidden_dim2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "def evaluate_model(model, X_val_tensor, y_val_tensor):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_predictions = model(X_val_tensor)\n",
    "        val_mae = mean_absolute_error(y_val_tensor.numpy(), val_predictions.numpy())\n",
    "    return val_mae\n",
    "\n",
    "def permutation_importance(model, X_val_tensor, y_val_tensor, baseline_mae, n_repeats=5):\n",
    "    importances = np.zeros(X_val_tensor.shape[1])\n",
    "    X_val_array = X_val_tensor.numpy()\n",
    "    y_val_array = y_val_tensor.numpy()\n",
    "    \n",
    "    for i in range(X_val_tensor.shape[1]):\n",
    "        permuted_maes = []\n",
    "        for _ in range(n_repeats):\n",
    "            X_permuted = X_val_array.copy()\n",
    "            np.random.shuffle(X_permuted[:, i])\n",
    "            X_permuted_tensor = torch.tensor(X_permuted, dtype=torch.float32)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                permuted_predictions = model(X_permuted_tensor)\n",
    "                permuted_mae = mean_absolute_error(y_val_array, permuted_predictions.numpy())\n",
    "                permuted_maes.append(permuted_mae)\n",
    "        \n",
    "        importances[i] = np.mean(permuted_maes) - baseline_mae\n",
    "    \n",
    "    return importances\n",
    "\n",
    "model = SimpleNN(X_train.shape[1])\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "baseline_mae = evaluate_model(model, X_val_tensor, y_val_tensor)\n",
    "print(f'Baseline MAE: {baseline_mae:.4f}')\n",
    "\n",
    "importances = permutation_importance(model, X_val_tensor, y_val_tensor, baseline_mae)\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "top_25_features = sorted_indices[:25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second run with the selected features and **hyperparameter optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.2069\n",
      "Best hyperparameters: {'hidden_dim1': 179, 'hidden_dim2': 6, 'learning_rate': 0.01595187774544761, 'batch_size': 42}\n"
     ]
    }
   ],
   "source": [
    "X_train_top_25 = X_train.iloc[:, top_25_features]\n",
    "X_val_top_25 = X_val.iloc[:, top_25_features]\n",
    "\n",
    "param_distributions = {\n",
    "    'hidden_dim1': randint(16, 256),\n",
    "    'hidden_dim2': randint(0, 256),\n",
    "    'learning_rate': uniform(0.01, 0.1),\n",
    "    'batch_size': randint(16, 128)\n",
    "}\n",
    "\n",
    "def create_model(input_dim, hidden_dim1, hidden_dim2):\n",
    "    return SimpleNN(input_dim=input_dim, hidden_dim1=hidden_dim1, hidden_dim2=hidden_dim2)\n",
    "\n",
    "def cross_val_score(model, X_train, y_train, criterion, optimizer, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    val_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        model_fold = create_model(X_train.shape[1], model.hidden_dim1, model.hidden_dim2)\n",
    "        optimizer_fold = optim.Adam(model_fold.parameters(), lr=model.learning_rate)\n",
    "        \n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        n_epochs = 20\n",
    "        for epoch in range(n_epochs):\n",
    "            model_fold.train()\n",
    "            optimizer_fold.zero_grad()\n",
    "            outputs = model_fold(X_train_fold_tensor)\n",
    "            loss = criterion(outputs, y_train_fold_tensor)\n",
    "            loss.backward()\n",
    "            optimizer_fold.step()\n",
    "        \n",
    "        val_score = evaluate_model(model_fold, X_val_fold_tensor, y_val_fold_tensor)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    return np.mean(val_scores)\n",
    "\n",
    "n_iter = 50\n",
    "best_score = float('inf')\n",
    "best_params = None\n",
    "\n",
    "for _ in range(n_iter):\n",
    "    params = {key: dist.rvs() for key, dist in param_distributions.items()}\n",
    "    model = create_model(X_train_top_25.shape[1], params['hidden_dim1'], params['hidden_dim2'])\n",
    "    model.learning_rate = params['learning_rate']\n",
    "    criterion = nn.L1Loss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'])\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train_top_25.values, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    val_score = cross_val_score(model, X_train_tensor, y_train_tensor, criterion, optimizer)\n",
    "    \n",
    "    if val_score < best_score:\n",
    "        best_score = val_score\n",
    "        best_params = params\n",
    "\n",
    "print(f'Best score: {best_score:.4f}')\n",
    "print(f'Best hyperparameters: {best_params}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third run with the best hyperparameters and **cross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cross-validated MAE: 0.2106\n"
     ]
    }
   ],
   "source": [
    "best_model = create_model(X_train_top_25.shape[1], best_params['hidden_dim1'], best_params['hidden_dim2'])\n",
    "best_model.learning_rate = best_params['learning_rate']\n",
    "criterion = nn.L1Loss()\n",
    "optimizer = optim.Adam(best_model.parameters(), lr=best_params['learning_rate'])\n",
    "\n",
    "def train_and_evaluate(model, X_train, y_train, criterion, optimizer, n_splits=5):\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "    val_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]\n",
    "        y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n",
    "        \n",
    "        model_fold = create_model(X_train.shape[1], model.hidden_dim1, model.hidden_dim2)\n",
    "        optimizer_fold = optim.Adam(model_fold.parameters(), lr=model.learning_rate)\n",
    "        \n",
    "        X_train_fold_tensor = torch.tensor(X_train_fold, dtype=torch.float32)\n",
    "        y_train_fold_tensor = torch.tensor(y_train_fold, dtype=torch.float32).view(-1, 1)\n",
    "        X_val_fold_tensor = torch.tensor(X_val_fold, dtype=torch.float32)\n",
    "        y_val_fold_tensor = torch.tensor(y_val_fold, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "        n_epochs = 20\n",
    "        for epoch in range(n_epochs):\n",
    "            model_fold.train()\n",
    "            optimizer_fold.zero_grad()\n",
    "            outputs = model_fold(X_train_fold_tensor)\n",
    "            loss = criterion(outputs, y_train_fold_tensor)\n",
    "            loss.backward()\n",
    "            optimizer_fold.step()\n",
    "        \n",
    "        val_score = evaluate_model(model_fold, X_val_fold_tensor, y_val_fold_tensor)\n",
    "        val_scores.append(val_score)\n",
    "    \n",
    "    return np.mean(val_scores)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_top_25.values, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "final_val_score = train_and_evaluate(best_model, X_train_tensor, y_train_tensor, criterion, optimizer)\n",
    "\n",
    "print(f'Final cross-validated MAE: {final_val_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rescaled Predicted Energies: [[48198.11 ]\n",
      " [45722.133]\n",
      " [45759.805]\n",
      " ...\n",
      " [45152.555]\n",
      " [45629.92 ]\n",
      " [47362.465]]\n"
     ]
    }
   ],
   "source": [
    "Data_test = pd.read_csv('AppML_InitialProject_test_regression.csv')\n",
    "\n",
    "Data_test = pd.DataFrame(scaler.fit_transform(Data_test), columns=Data_test.columns)\n",
    "X_test_25 = Data_test.iloc[:, top_25_features]\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test_25.values, dtype=torch.float32)\n",
    "\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = best_model(X_test_tensor).numpy()\n",
    "\n",
    "Rescaled_y_pred_test = y_std * predictions + y_mean\n",
    "print('Rescaled Predicted Energies:', Rescaled_y_pred_test)\n",
    "Rescaled_y_pred_test = [val for sublist in Rescaled_y_pred_test for val in np.array(sublist).flatten()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving (set to false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'solutions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "Write = False\n",
    "if Write:\n",
    "    \n",
    "    top_25_variable_names = X.columns[top_25_features]\n",
    "    variables = top_25_variable_names\n",
    "    csv_file_path = os.path.join(folder_name, 'Regression_Pytorch_VariableList.csv')\n",
    "\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for variable in variables:\n",
    "            writer.writerow([variable])\n",
    "    \n",
    "    data = Rescaled_y_pred_test\n",
    "\n",
    "    csv_file_path = os.path.join(folder_name, 'Regression_Pytorch.csv')\n",
    "    \n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for index, item in enumerate(data, start=0):\n",
    "            writer.writerow([index, item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
