{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from hyperopt import hp, tpe, fmin, Trials, space_eval\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "Data_train = pd.read_csv('AppML_InitialProject_train.csv')\n",
    "Data_train = Data_train[Data_train['p_Truth_isElectron'] == 1]\n",
    "\n",
    "y_mean = np.copy(np.mean(Data_train['p_Truth_Energy']))\n",
    "y_std = np.copy(np.std(Data_train['p_Truth_Energy']))\n",
    "\n",
    "Data_train = pd.DataFrame(scaler.fit_transform(Data_train), columns=Data_train.columns)\n",
    "\n",
    "X = Data_train.drop(['p_Truth_isElectron', 'p_Truth_Energy'], axis=1)\n",
    "y = Data_train['p_Truth_Energy']  # Target variable for regression\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "xgb_reg = xgb.XGBRegressor(objective='reg:squarederror', learning_rate=0.1,\n",
    "                           max_depth=8, n_estimators=300,\n",
    "                           seed=42, n_jobs=-1, eval_metric='mae')\n",
    "\n",
    "start_time = time.time()\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the most important features using **feature_importances_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = xgb_reg.feature_importances_\n",
    "sorted_indices = importances.argsort()[::-1]\n",
    "top_20_indices = sorted_indices[:25]\n",
    "top_20_features = X.columns[top_20_indices]\n",
    "\n",
    "X_train_20 = X_train[top_20_features]\n",
    "X_val_20 = X_val[top_20_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second run using the most important features, **cross validation** and **hyperparameter optimization (bayesian)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [02:28<00:00, 14.86s/trial, best loss: 0.15149056150933735]\n",
      "Best Hyperparameters: {'colsample_bytree': 0.9206778001753837, 'gamma': 0.1308725613479863, 'learning_rate': 0.12712692444465476, 'max_depth': 13, 'min_child_weight': 8.09842442235597, 'n_estimators': 600, 'subsample': 0.9598991115569738}\n",
      "Mean Absolute Error (MAE): 0.136768140574989\n",
      "Elapsed time: 24.175472259521484 seconds\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "    'learning_rate': hp.uniform('learning_rate', 0.01, 0.3),\n",
    "    'max_depth': hp.choice('max_depth', np.arange(3, 17, dtype=int)),\n",
    "    'subsample': hp.uniform('subsample', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_bytree', 0.0, 1.0),\n",
    "    'gamma': hp.uniform('gamma', 0.0, 1.0),\n",
    "    'n_estimators': hp.choice('n_estimators', np.arange(100, 1000, 100, dtype=int)),\n",
    "    'min_child_weight': hp.uniform('min_child_weight', 0, 10)\n",
    "}\n",
    "\n",
    "def objective(params):\n",
    "    model = xgb.XGBRegressor(objective='reg:squarederror', seed=42, **params, n_jobs=-1, eval_metric='mae')\n",
    "    scores = cross_val_score(model, X_val_20, y_val, cv=5, scoring='neg_mean_absolute_error')\n",
    "    return -np.mean(scores)\n",
    "\n",
    "trials = Trials()\n",
    "best = fmin(fn=objective, space=space, algo=tpe.suggest, max_evals=10, trials=trials)\n",
    "\n",
    "best_params = space_eval(space, best)\n",
    "\n",
    "best_model = xgb.XGBRegressor(objective='reg:squarederror', seed=42, **best_params, n_jobs=-1, eval_metric='mae')\n",
    "\n",
    "start_time = time.time()\n",
    "best_model.fit(X_train_20, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "y_pred = best_model.predict(X_val_20)\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "print(\"Mean Absolute Error (MAE):\", mae)\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time:\", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Energies: [-0.7943728   0.6129045   0.3662371  ... -0.6280874  -0.73131466\n",
      " -0.69969213]\n",
      "Rescaled Predicted Energies: [19423.332 98539.59  84672.1   ... 28771.793 22968.422 24746.223]\n"
     ]
    }
   ],
   "source": [
    "Data_test = pd.read_csv('AppML_InitialProject_test_regression.csv')\n",
    "\n",
    "X_test = pd.DataFrame(scaler.fit_transform(Data_test), columns=Data_test.columns)\n",
    "X_test_20 = X_test[top_20_features]\n",
    "\n",
    "y_pred_test = best_model.predict(X_test_20)\n",
    "print(\"Predicted Energies:\", y_pred_test)\n",
    "\n",
    "Rescaled_y_pred_test = y_std*y_pred_test + y_mean\n",
    "print('Rescaled Predicted Energies:', Rescaled_y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = 'solutions'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "Write = False\n",
    "if Write:\n",
    "    top_20_features_list = top_20_features.tolist()\n",
    "    variables = top_20_features\n",
    "\n",
    "    csv_file_path = os.path.join(folder_name, 'Regression_XGBoost_VariableList.csv')\n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for variable in variables:\n",
    "            writer.writerow([variable])\n",
    "    \n",
    "    data = Rescaled_y_pred_test\n",
    "    csv_file_path = os.path.join(folder_name, 'Regression_XGBoost.csv')\n",
    "    \n",
    "    with open(csv_file_path, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        for index, item in enumerate(data, start=0):\n",
    "            writer.writerow([index, item])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
